{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNFTrGLfcbaSui8acqrig4O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ADozoMRedR8T"},"outputs":[],"source":["import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","import glob\n","import math\n","\n","from sklearn.linear_model import LinearRegression\n","from google.colab.patches import cv2_imshow as imshow\n","\n","class img_preprocessing() :\n","  def __init__(self, img) :\n","    self.self = self\n","    self.img = img\n","  \n","  # contrast 함수\n","  def contrast_roi(img, low, high):\n","    h, w = img.shape\n","    img_ = np.zeros(img.shape, dtype=np.uint8)\n","    for y in range(h):\n","      for x in range(w):\n","        temp = int((255 / (high - low)) * (img[y][x] - low))\n","        if temp > 255:\n","          img_[y][x] = 255\n","        elif temp < 0:\n","          img_[y][x] = 0\n","        else:\n","          img_[y][x] = temp\n","    return img_\n","\n","  # 밝기 조정\n","  def bright_ness(img):\n","    cols, rows = img.shape[:2]\n","    brightness = np.sum(img) / (255 * cols * rows)\n","    return brightness\n","\n","  # 마스크 생성\n","  def make_mask(img):\n","      img1 = img.copy()\n","      out1 = img1.copy()\n","\n","      img1 = cv2.cvtColor(img1, cv2.COLOR_RGB2BGR)\n","      img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2Lab)\n","      out2 = img1.copy()\n","\n","      blur_k = int((img1.mean()*0.5)//2)*2+1\n","      img1 = cv2.medianBlur(img1, blur_k)\n","\n","      img1 = cv2.cvtColor(img1, cv2.COLOR_Lab2BGR)\n","      img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n","\n","      if img1.mean() > 100 : \n","        th = img1.mean()*0.94\n","      else : \n","        th = img1.mean()\n","\n","      ret, img1 = cv2.threshold(img1, th, 255, cv2.THRESH_BINARY)\n","\n","      contours, hierarchy = cv2.findContours(img1, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","      max_cnt = max(contours, key=cv2.contourArea)\n","      mask = np.zeros(img1.shape, dtype=np.uint8)\n","\n","      cv2.drawContours(mask, [max_cnt], -1, (255,255,255), -1)\n","      \n","      k = cv2.getStructuringElement(cv2.MORPH_RECT, (8,8))\n","      mask = cv2.dilate(mask,k)\n","\n","\n","      return mask\n","\n","  # 마스크 기준으로 자르기\n","  def cut_mask(img, mask):\n","      img2 = img.copy()\n","      height, width = img2.shape[:2]\n","      mask_list = mask.tolist()\n","      \n","      for y in range(int(height*0.05),height):\n","          if max(mask[y,int(width*0.3):int(width*0.7)]) > 0:\n","              start_y = y-int(height*0.05)\n","              break\n","              \n","      for x in range(int(width*0.05),width):\n","          if max(mask[int(height*0.3):int(height*0.7),x]) > 0:\n","              start_x = x-int(width*0.05)\n","              break\n","              \n","      for x in range(int(width*0.95),-1,-1):\n","          if max(mask[int(height*0.3):int(height*0.7),x]) > 0:\n","              end_x = x+int(width*0.05)\n","              break\n","              \n","      cut_index = 0\n","      if mask_list[height-1][-1] == 255 or mask_list[height-1][0] == 255:\n","          for n in reversed(range(height)):\n","              if mask_list[n][0] == 0 or mask_list[n][-1] == 0:\n","                  cut_index = n\n","                  break\n","                  \n","      if cut_index == 0:\n","          cut_index = height\n","\n","      img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY) \n","\n","      img2 = img2[start_y:(cut_index-1),start_x:end_x]\n","      mask = mask[start_y:(cut_index-1),start_x:end_x]\n","\n","      masked = cv2.bitwise_and(img2, mask)\n","\n","      return masked\n","\n","  def masked_ro(img):\n","      img3 = img.copy()\n","      h, w = img3.shape[:2]\n","      img3 = cv2.cvtColor(img3, cv2.COLOR_RGB2BGR)\n","      gray = cv2.cvtColor(img3, cv2.COLOR_BGR2GRAY)\n","\n","      ret, th = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n","      th_li = th.tolist()\n","\n","      for i in reversed(range(h)):\n","        if th_li[i][0] == 0 and th_li[i][-1] == 0:\n","          lower = i\n","          break\n","\n","      if lower == h - 1:\n","        lower = int(h*0.9)\n","\n","      slice5 = int(len(th)*0.05)\n","      upper = lower - slice5\n","\n","      x,y = [],[]\n","\n","      for i in range(slice5):\n","        cnt = th_li[i + upper].count(255)\n","        index = th_li[i + upper].index(255)\n","\n","        x.append([i+upper])\n","        y.append([int((index*2 + cnt - 1)/2)])\n","\n","      model = LinearRegression()\n","      model.fit(X=x,y=y)\n","\n","      # -----------------------------------------------------------------------------------\n","      angle = math.atan2(h - 0, int(model.predict([[h]])) - int(model.predict([[0]])))*180/math.pi\n","\n","      M = cv2.getRotationMatrix2D((w/2,h/2), angle-90, 1)\n","      rotate = cv2.warpAffine(img3, M, (w, h))\n","\n","      for i in range(len(th[-1])):\n","          if th[-1][i] == 255:\n","              start_x = i\n","              break\n","\n","      for i in range(len(th[-1])):\n","          if th[-1][i] == 255:\n","              end_x = i\n","\n","      s_point = h - int((int(model.predict([[h]])-start_x)) * math.tan(math.pi*((90-angle)/180)))\n","      e_point = h - int((end_x - int(model.predict([[h]]))) * math.tan(math.pi*((angle-90)/180)))\n","\n","      point = max(s_point, e_point)\n","      img_ro = rotate[:point]\n","\n","      return img_ro\n","\n","  def bone_extraction(img,a,b,d,e):\n","    img1 = img\n","    if img_preprocessing.bright_ness(img1) > 0.8:\n","      img1 = np.clip(img1 - 80., 0, 255).astype(np.uint8)\n","    elif img_preprocessing.bright_ness(img1) > 0.75:\n","      img1 = np.clip(img1 - 50., 0, 255).astype(np.uint8)\n","    elif img_preprocessing.bright_ness(img1) > 0.65:\n","      img1 = np.clip(img1 - 30., 0, 255).astype(np.uint8)\n","    else: img1 = np.clip(img1 - 10., 0, 255).astype(np.uint8)\n","\n","    img1 = cv2.cvtColor(img1, cv2.COLOR_RGB2BGR)\n","    img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2Lab)\n","    out1 = img1.copy()\n","\n","    k = cv2.getStructuringElement(cv2.MORPH_CROSS, (a, a))\n","    img1 = cv2.morphologyEx(img1, cv2.MORPH_TOPHAT, k)\n","\n","    img1 = cv2.bilateralFilter(img1,-1, d, e)\n","\n","    img1 = cv2.cvtColor(img1, cv2.COLOR_Lab2BGR)\n","    img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n","    out1 = img1.copy()\n","\n","    img1 = cv2.normalize(img1, None, 0, 255, cv2.NORM_MINMAX)\n","    img1 = cv2.equalizeHist(img1)\n","    clahe = cv2.createCLAHE(clipLimit=1.0, tileGridSize=(3,3))\n","    img1 = clahe.apply(img1)\n","\n","    ret, mask = cv2.threshold(img1, np.mean(img1), 255, cv2.THRESH_BINARY)\n","    \n","    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    cv2.drawContours(mask, contours, -1, (255,255,255), -1)\n","\n","\n","    #### 강 조\n","    img2 = img.copy()\n","    if img_preprocessing.bright_ness(img2) > 0.8:\n","      img2 = np.clip(img2 - 80., 0, 255).astype(np.uint8)\n","    elif img_preprocessing.bright_ness(img2) > 0.75:\n","      img2 = np.clip(img2 - 50., 0, 255).astype(np.uint8)\n","    elif img_preprocessing.bright_ness(img2) > 0.65:\n","      img2 = np.clip(img2 - 30., 0, 255).astype(np.uint8)\n","    else: img2 = np.clip(img2 - 10., 0, 255).astype(np.uint8)\n","\n","    # 모폴로지\n","    k2 = cv2.getStructuringElement(cv2.MORPH_CROSS,(b,b))\n","    img2 = cv2.morphologyEx(img2, cv2.MORPH_TOPHAT, k2)\n","\n","    # contrast\n","    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n","    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n","\n","    if img2.mean() <= 15:\n","        low = img2.mean() * 3.2\n","        high = img2.mean() * 3.6\n","    elif img2.mean() <= 20:\n","        low = img2.mean() * 3\n","        high = img2.mean() * 3.6\n","    else:\n","        low = img2.mean() * 3\n","        high = img2.mean() * 3.7\n","\n","    img2 = cv2.blur(img2,(2,2))\n","    img2 = img_preprocessing.contrast_roi(img2, low, high)\n","\n","    # 컨투어\n","    contours, hierarchy = cv2.findContours(img2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    cv2.drawContours(img2, contours, -1, (255, 255, 255), -1)\n","\n","    img2 = cv2.bitwise_and(img2, mask) \n","    img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n","    img2 = cv2.blur(img2,(2,2))\n","    img2 = cv2.resize(img2, (600, 800))\n","\n","    return img2\n","\n","  def preprocession(img):\n","    mask = img_preprocessing.make_mask(img)\n","    masked = img_preprocessing.cut_mask(img, mask)\n","    img_ro = img_preprocessing.masked_ro(masked)\n","    img = img_preprocessing.bone_extraction(img_ro, 60,55,50,25)\n","    \n","    return img\n","\n","from tqdm import tqdm\n","\n","def save(img_path, save_path) :\n","  gender_li = [\"Female\", \"Male\"]\n","  img_path = img_path\n","\n","  for g in gender_li :\n","    start, end = 0, 0\n","    if g == \"Female\" :\n","      start, end = 1, 573\n","    elif g == \"Male\" :\n","      start, end = 1, 666\n","\n","    for i in tqdm(range(start, end)) :\n","      try :\n","        img = cv2.imread(img_path+f\"{g}/{i}_{g[0]}.jpg\", cv2.IMREAD_COLOR)\n","        img = img_preprocessing.preprocession(img)\n","        #imshow(img)  \n","        cv2.imwrite(f'{save_path}{g}/{i}_{g[0]}.jpg',img )\n","      except :\n","        print(f\"오류 > {i}_{g[0]}.jpg\")\n","        continue"]},{"cell_type":"code","source":[],"metadata":{"id":"1uwlFWhYdcGZ"},"execution_count":null,"outputs":[]}]}